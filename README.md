# Self-Supervised Learning for Small Object Detection and Fine-Tuning with YOLOv8
This repository contains a project focused on leveraging YOLOv8 for self-supervised learning (SSL) using SimCLR principles and fine-tuning it on a labeled dataset. The project includes SSL training, fine-tuning, supervised training, and detailed evaluation tools to compare the benefits of SSL-pretrained backbones.

## Project Overview
This project explores the integration of YOLOv8 with SimCLR for self-supervised representation learning, followed by fine-tuning on a labeled dataset.

![image4](https://github.com/user-attachments/assets/61beb9a4-b33f-4632-9426-68d9629826fc)

* The model structure:
![model structure](https://github.com/user-attachments/assets/1891baea-cb40-4ce9-a280-1951adb63d02)
For YOLOv8, the backbone is the first 10 layers. You can check the [yaml model definition](https://github.com/ultralytics/ultralytics/blob/1d13575ba16623d711c682118ee118615383ba99/ultralytics/cfg/models/v8/yolov8.yaml) to verify that.

## ğŸ§­ Workflow Summary

### 1. **Unlabeled Dataset of Aerial Images**
- The project begins with a unlabeled dataset of **aerial images**, rich in small objects (vehicles), but **without annotations**.

### 2. **Initial Object Detection using a Pretrained Model**
- A **pretrained object detection model** (e.g., YOLOv8 with pretrained weights) was used to perform **weak supervision**:
  - Run predictions on the aerial images.
  - Extract bounding boxes for detected vehicles.
  - Treat the detected objects as **pseudo-labeled vehicles**.

### 3. **Cropping Detected Vehicles**
- From each bounding box, a square crop was extracted around the vehicle.
- These cropped patches represent the **"vehicle" class**.
- Saved as `cars_*.jpg` files.

### 4. **Generating Background Crops**
- To balance the dataset and provide negative examples:
  - An equal number of **random background crops** (with no vehicles) were taken from the same aerial images.
  - These represent the **"background" class**.
  - Saved as `background_*.jpg` files.

### 5. **Constructing the SSL Dataset**
- The final dataset contains:
  - Cropped vehicles â†’ `car_001.jpg`, `car_002.jpg`, ...
  - Cropped backgrounds â†’ `background_001.jpg`, `background__002.jpg`, ...
- This allows for constructing contrastive batches with clear **semantic meaning** between classes.


## ğŸ” Contrastive Learning Strategies

Using the constructed dataset, **3 SSL strategies** were implemented:

### 1. **Unsupervised Contrastive Learning (SimCLR-style)**
- Each batch contains random images from the dataset.
- Every image is augmented twice â†’ forming positive pairs.
- All other images act as negatives (even if there is image from the same class)
- No class labels are used.

### 2. **Supervised Contrastive Learning â€“ Without Augmentation**
- Images are grouped by class (vehicle or background).
- Positive pairs are two different images from the same class.
- No augmentations applied.

### 3. **Supervised Contrastive Learning â€“ With Augmentation** âœ…
- The most effective method for this dataset:
  - **Anchor**: cropped vehicle image(1 image)
  - **Positive**: an augmented version of the same image (1 image)
  - **Negatives**: randomly sampled background crops (batch size - 2 images)
- Combines **label supervision** and **augmentation diversity**.

## ğŸ¯ Goal

To train a robust feature extractor that distinguishes between small objects (vehicles) and background in aerial imagery.

. The main workflow includes:

#### 1. Self-Supervised Pretraining (SimCLR):
* Trains YOLOv8â€™s backbone using contrastive learning (SimCLR) on unlabeled image crops.
* **Data Augmentations:**  
  During SSL training, we apply several augmentations to the input images to generate similar yet distinct views for contrastive learning. These augmentations include:  

  ```python
  # Define the data transforms
  data_transforms = transforms.Compose([
      transforms.RandomResizedCrop(640),               # Crop and resize
      transforms.RandomHorizontalFlip(),              # Random horizontal flip
      transforms.ColorJitter(                         # Random color changes
          brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1
      ),
      transforms.ToTensor(),                          # Convert image to Tensor
      transforms.Normalize([0.485, 0.456, 0.406],     # Normalize image
                           [0.229, 0.224, 0.225])
  ])
  ```
   * Example Augmented Images:
     
    ![image](https://github.com/user-attachments/assets/2b6c677d-1ee1-483e-aca8-4574af3f40e0)

* Optimizes feature representations using the InfoNCE loss function.
  

#### 2. Fine-Tuning:
* Fine-tunes the pretrained YOLOv8 backbone on labeled datasets.
* Freezes the backbone and trains only the head for classification.

#### 3. Supervised Training Baseline:
* Trains YOLOv8 from scratch in a fully supervised manner for baseline comparison.

#### 4. Evaluation:
* Compares the SSL-pretrained fine-tuned model with the fully supervised baseline.
* Provides visualizations such as loss graphs, confusion matrices, and accuracy metrics.


## Dataset Preparation for Project

### Step 1: Selecting the Dataset

The first step in preparing the dataset for the project is to choose a suitable dataset. In this project, the **AITOD** dataset was selected. 
It contain 1000 images.

### Step 2: Dataset Location

The dataset is divided into two main directories:
- **IMAGES**: Contains the images.
- **LABELS**: Contains the labels.

The data is located in the following directory:
```
C:\Users\shir-\PycharmProjects\ssl_yolo\datasets\train
```

### Step 3: Splitting the Dataset

After selecting the dataset, the next step is to split the data into two groups:
- **80%** of the data will be used for SSL TRAIN. 
- **20%** of the data will be used for SUPERVISED.

### Step 4: Splitting the SUPERVISED dataset

- **75%** for TRAIN. 150 images with 2823 objects.
- **15%** for VALIDATION (VAL). 30 images with 923 objects
- **10%** for TEST. 20 images with 528 objects.

### Step 5: Processing the SSL dataset

In this step, the SSL dataset is processed by cropping all objects in the image using the labels. This includes:
- Identifying the objects in each image according to the labels (LABELS).
- Cropping the objects from the images.
- Creating **crops objects** files for all vehicles in the images.
- There are 16,000 crops images.

### Step 6: Creating random crops of background 

In this step, random background crops are created from the images. This includes:
- Selecting random areas in the image that do not include labeled objects.
- Cropping the random areas.
- Saving the **random crops** files for background to balance the data.
- There are 16,000 crops images.


### Step 7: Merge the crops of the vehicles and background to one mix folder:
This step merges vehicle and background crops into a single folder, allowing for random sampling of mixed, unlabeled images during SSL training to ensure diverse and balanced batches.
- There are **32,000** mix crops unlabeled images.


### Step 8: Splitting the SSL dataset:
- **75%** for TRAIN.  24,033 objects.
- **15%** for VALIDATION (VAL). 4806 objects
- **10%** for TEST.  3205 objects.


  
## Project Structure

```python

project_root/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ count_labels/           # Tools for counting objects in datasets.
â”‚   â”‚   â”œâ”€â”€ __pycache__/        # Compiled Python files for count_labels.
â”‚   â”‚   â””â”€â”€ count_objects_in_split.py # Counts objects in dataset splits.
â”‚   â”œâ”€â”€ crops/                  # Tools for creating and managing cropped datasets.
â”‚   â”‚   â”œâ”€â”€ __pycache__/        # Compiled Python files for crops.
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Initialization for the crops module.
â”‚   â”‚   â”œâ”€â”€ image_crop.py       # Functionality for cropping images.
â”‚   â”‚   â””â”€â”€ random_crops.py     # Generates random cropped images.
â”‚   â””â”€â”€ split/                  # Tools for dataset splitting.
â”‚       â”œâ”€â”€ __pycache__/        # Compiled Python files for split.
â”‚       â”œâ”€â”€ __init__.py         # Initialization for the split module.
â”‚       â”œâ”€â”€ split_ssl_dataset.py # Splits datasets for SSL training.
â”‚       â”œâ”€â”€ split_supervised_dataset.py # Splits datasets for supervised training.
â”‚       â””â”€â”€ split_to_ssl_and_supervised.py # Splits datasets into SSL and supervised subsets.
â”‚
â”œâ”€â”€ loss_functions/
â”‚   â””â”€â”€ info_nce.py             # Implementation of the InfoNCE loss function for SimCLR.
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ ssl_model.py            # Defines YOLOv8-based SSL model with projection head.
â”‚   â”œâ”€â”€ yolov8.py               # Core YOLOv8 backbone and head definitions.
â”‚
â”œâ”€â”€ trainers_ssl/
â”‚   â”œâ”€â”€ train.py                # Training loop for SSL.
â”‚   â”œâ”€â”€ validate.py             # Validation loop for SSL.
â”‚   â””â”€â”€ test.py                 # Testing loop for SSL.
â”‚
â”œâ”€â”€ trainers_supervised/
â”‚   â”œâ”€â”€ train.py                # Training loop for supervised models.
â”‚   â”œâ”€â”€ validate.py             # Validation loop for supervised models.
â”‚   â””â”€â”€ test.py                 # Testing loop for supervised models.
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ ssl_train/              # Stores logs, graphs, and models from SSL training.
â”‚   â”œâ”€â”€ fine_tuning/            # Stores logs, graphs, and models from fine-tuning.
â”‚   â””â”€â”€ supervised_train/       # Stores logs, graphs, and models from supervised training.
â”‚
â”œâ”€â”€ simclr_train.py             # Main script for training YOLOv8 with SSL (SimCLR).
â”œâ”€â”€ fine_tune.py                # Main script for fine-tuning using SSL-pretrained weights.
â”œâ”€â”€ supervised_train.py         # Main script for supervised YOLOv8 training.
â”œâ”€â”€ README.md                   # Project description, instructions, and results.
â”œâ”€â”€ main.py                     # prepare all the datasets.
â””â”€â”€ .gitignore                  # Specifies files and folders to exclude from version control.



```


## Installation
### Prerequisites

Python 3.8+
PyTorch with CUDA support (if using a GPU)
YOLOv8 installed via pip install ultralytics

## Usage 
### 1. Self-Supervised Pretraining (SimCLR)

Run SSL- SimCLR training on cropped images using SimCLR principles:

```python
python3 simclr_train.py

```

### 2. Fine-Tuning with SSL Weights
Fine-tune the YOLOv8 model using the SSL-pretrained backbone:

```python
python3 fine_tuning.py
```

### 3. Supervised Baseline
Train YOLOv8 from scratch on labeled datasets:

```python
python3 supervised_train.py
 ```

### 4. Visualizations and Evaluation

* Results will be saved in the output folder.
* Check accuracy graphs, loss plots, and confusion matrices.

## Results

## 1. Loss and Accuracy Over Epochs

### Supervised Baseline:

* Test Accuracy: 

### Fine-Tuned (SSL):

* Test Accuracy: 

## 2. Confusion Matrix

### Supervised Baseline:


### Fine-Tuned (SSL):




## Resources
- [SimCLR Tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial17/SimCLR.html)
- [Yolov8 Architecture](https://github.com/ultralytics/ultralytics/issues/189)
- [Yolov8 Yaml file](https://github.com/ultralytics/ultralytics/blob/1d13575ba16623d711c682118ee118615383ba99/ultralytics/cfg/models/v8/yolov8.yaml)
- [SimCLR information](https://research.google/blog/advancing-self-supervised-and-semi-supervised-learning-with-simclr)
